{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from sklearn.utils import shuffle\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 1.66666667,  2.        ,  2.        , ...,  1.66666667,\n",
       "           1.66666667,  1.66666667],\n",
       "         [ 1.66666667,  1.66666667,  1.66666667, ...,  1.66666667,\n",
       "           1.66666667,  1.66666667],\n",
       "         [ 1.66666667,  1.66666667,  1.66666667, ...,  1.66666667,\n",
       "           1.66666667,  1.66666667],\n",
       "         ...,\n",
       "         [ 2.        ,  2.        ,  1.66666667, ...,  3.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 1.66666667,  1.66666667,  1.66666667, ...,  5.        ,\n",
       "           5.66666667,  3.33333333],\n",
       "         [ 2.        ,  1.66666667,  2.        , ...,  5.        ,\n",
       "           5.66666667,  6.        ]],\n",
       " \n",
       "        [[ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 7.66666667,  4.        ,  4.66666667, ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         ...,\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ]],\n",
       " \n",
       "        [[ 2.        ,  2.        ,  2.        , ..., 34.33333333,\n",
       "          29.        , 22.33333333],\n",
       "         [ 2.        ,  2.        ,  2.        , ..., 39.        ,\n",
       "          30.33333333, 26.33333333],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  4.        ,\n",
       "           5.33333333, 36.66666667],\n",
       "         ...,\n",
       "         [ 2.        ,  2.        ,  2.33333333, ...,  2.33333333,\n",
       "           2.33333333,  2.33333333],\n",
       "         [ 2.        ,  2.33333333,  2.66666667, ...,  2.33333333,\n",
       "           2.33333333,  2.33333333],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.33333333,\n",
       "           2.33333333,  2.33333333]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.33333333,  2.        ],\n",
       "         ...,\n",
       "         [ 2.66666667,  4.33333333,  4.        , ...,  8.        ,\n",
       "          37.66666667, 15.66666667],\n",
       "         [ 5.        , 10.66666667,  9.66666667, ...,  2.33333333,\n",
       "          12.33333333, 20.33333333],\n",
       "         [ 4.        ,  9.66666667,  8.33333333, ...,  2.33333333,\n",
       "           2.33333333,  2.66666667]],\n",
       " \n",
       "        [[ 2.33333333,  2.33333333,  2.        , ..., 17.        ,\n",
       "           7.        ,  2.33333333],\n",
       "         [ 4.        ,  2.        ,  2.33333333, ..., 26.        ,\n",
       "          15.66666667,  2.66666667],\n",
       "         [ 3.66666667,  2.        ,  2.        , ..., 23.33333333,\n",
       "           6.66666667,  2.        ],\n",
       "         ...,\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.33333333,  2.        ],\n",
       "         [ 2.33333333,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 3.        ,  3.66666667,  3.66666667, ...,  2.        ,\n",
       "           2.        ,  2.        ]],\n",
       " \n",
       "        [[ 1.66666667,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.33333333,  2.33333333],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           3.33333333,  2.33333333],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.33333333,\n",
       "           2.33333333,  2.        ],\n",
       "         ...,\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ],\n",
       "         [ 2.        ,  2.        ,  2.        , ...,  2.        ,\n",
       "           2.        ,  2.        ]]]), array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_classes = 3\n",
    "epochs = 12\n",
    "kSize = 10\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 800, 800\n",
    "#load the training and test data\n",
    "h5f = h5py.File('g4data.h5','r')\n",
    "# the data, split between train and test sets\n",
    "X = np.array(h5f['x_data_images'])\n",
    "y = np.array(h5f['y_data_images'])\n",
    "# convert class vectors to binary class matrices\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#add model layers\n",
    "#layer 1\n",
    "model.add(Conv2D(64, (kSize, kSize), input_shape = (64, 64, 1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#layer 2\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#final layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "#output\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 524 samples, validate on 28 samples\n",
      "Epoch 1/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0690 - accuracy: 0.9752 - val_loss: 0.4356 - val_accuracy: 0.8214\n",
      "Epoch 2/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0753 - accuracy: 0.9733 - val_loss: 1.2781 - val_accuracy: 0.6786\n",
      "Epoch 3/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.1756 - accuracy: 0.9466 - val_loss: 0.7861 - val_accuracy: 0.7500\n",
      "Epoch 4/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0875 - accuracy: 0.9733 - val_loss: 0.6965 - val_accuracy: 0.7500\n",
      "Epoch 5/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0285 - accuracy: 0.9924 - val_loss: 0.4121 - val_accuracy: 0.8214\n",
      "Epoch 6/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0221 - accuracy: 0.9885 - val_loss: 0.1622 - val_accuracy: 0.9643\n",
      "Epoch 7/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0378 - accuracy: 0.9828 - val_loss: 1.1449 - val_accuracy: 0.7143\n",
      "Epoch 8/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.8100 - val_accuracy: 0.7500\n",
      "Epoch 9/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0365 - accuracy: 0.9809 - val_loss: 0.7493 - val_accuracy: 0.7143\n",
      "Epoch 10/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 1.0451 - val_accuracy: 0.7857\n",
      "Epoch 11/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0312 - accuracy: 0.9924 - val_loss: 4.1855 - val_accuracy: 0.4643\n",
      "Epoch 12/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.1836 - accuracy: 0.9523 - val_loss: 1.2971 - val_accuracy: 0.7143\n",
      "Epoch 13/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0465 - accuracy: 0.9828 - val_loss: 1.0841 - val_accuracy: 0.7857\n",
      "Epoch 14/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0242 - accuracy: 0.9885 - val_loss: 1.3261 - val_accuracy: 0.7857\n",
      "Epoch 15/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0511 - accuracy: 0.9828 - val_loss: 1.0566 - val_accuracy: 0.8214\n",
      "Epoch 16/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 1.6180 - val_accuracy: 0.7143\n",
      "Epoch 17/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.1190 - accuracy: 0.9752 - val_loss: 0.6458 - val_accuracy: 0.8929\n",
      "Epoch 18/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0407 - accuracy: 0.9828 - val_loss: 0.4471 - val_accuracy: 0.8929\n",
      "Epoch 19/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 0.7828 - val_accuracy: 0.7500\n",
      "Epoch 20/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.5363 - val_accuracy: 0.8214\n",
      "Epoch 21/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0741 - accuracy: 0.9790 - val_loss: 2.0903 - val_accuracy: 0.6786\n",
      "Epoch 22/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0641 - accuracy: 0.9714 - val_loss: 0.9622 - val_accuracy: 0.7857\n",
      "Epoch 23/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0099 - accuracy: 0.9943 - val_loss: 0.7269 - val_accuracy: 0.8571\n",
      "Epoch 24/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.9423 - val_accuracy: 0.8929\n",
      "Epoch 25/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0453 - accuracy: 0.9885 - val_loss: 0.9156 - val_accuracy: 0.8571\n",
      "Epoch 26/26\n",
      "524/524 [==============================] - 7s 13ms/step - loss: 0.0380 - accuracy: 0.9847 - val_loss: 1.1414 - val_accuracy: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e330611e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(x_train.shape, '\\n', y_train.shape, '\\n', x_test.shape, '\\n', y_test.shape)\n",
    "X = X.reshape(-1, 64, 64, 1)\n",
    "model.fit(X, y,  batch_size = 4, epochs = 26, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
